}
pasta_opaop_ano   <- sprintf("%s/%s", pasta_aop_lpsolve, ano)
rm(versao_solucao)
# Osm_ids que faziam parte da ttmatrix utilizada
osm_ids <- sprintf('%s/ttmatrix_osmids_%s_res09_%smin.csv', pasta_opaop_ttmat, ano, tempo_max)
osm_ids <- read_delim(osm_ids, delim = ';', col_types = 'cccd')
# osm_ids %>% select(orig, dest) %>% distinct() # 2019 - 245.187
head(osm_ids)
# Desmembrar coluna hex_id_alt em origem, destino e número da alternativa da rota
osm_ids <-
osm_ids %>%
mutate(hex_id_alt = str_replace(hex_id_alt,
'^([a-z0-9]{6})-([a-z0-9]{6})-([0-9])',
'89a81\\1ffff-89a81\\2ffff-\\3')) %>%
separate(hex_id_alt, into = c('orig', 'dest', 'alt'), sep = '-', remove = TRUE)
head(osm_ids)
ciclo_futura <- sprintf('%s/sao_paulo_osm_filtrado_com_qgis_id_redes_cicloviarias_2019_2028.gpkg', pasta_graphhopper)
ciclo_futura <- read_sf(ciclo_futura) %>% st_drop_geometry()
# # Redes: '2019', 'referencia', 'NA'
# ciclo_futura %>% filter(osm_id == '264984110')
# ciclo_futura %>% select(rede_cicloviaria) %>% distinct()
# Puxar osm_ids com pelo menos 50% de extensão de rede cicloviária
ciclo_futura <-
ciclo_futura %>%
# filter(osm_id == '264984110') %>%
# Tudo o que for NA vai ser marcado como 'sem rede', enquanto as redes 2019 e
# de referência vão ser marcadas ambas como de referência
mutate(rede = ifelse(is.na(rede_cicloviaria), 'sem rede', 'referencia')) %>%
group_by(osm_id, rede) %>%
summarise(ext = sum(length_m)) %>%
mutate(perc = ext / sum(ext) * 100) %>%
ungroup() %>%
# Manter somente os osm_ids com mais do que 50% de extensão com rede cicloviária
filter(rede == 'referencia' & perc > 50)
# Corrigir: nos osm_ids com infra cicloviária calculada percorrida pelo routing,
# tudo o que não estiver na rede de referência (2019 + 2028) e que tenha pelo
# menos x% de extensão com reder cicloviária, vai ser remarcado
osm_ids <-
osm_ids %>%
mutate(infra_ciclo = ifelse(osm_way_id %in% ciclo_futura$osm_id, infra_ciclo, as.character(NA))) %>%
filter(!is.na(infra_ciclo))
pasta_aop_rev     <- sprintf("%s/12_aop_revisitado", pasta_dados)
pasta_aoprv_alter <- sprintf("%s/03_alternatives_2019_2028", pasta_aop_rev)
osm_ids
sprintf('%s/tmp_infra_ciclo_%s_revisada.csv', pasta_aoprv_alter, ano)
# Gravar resultados para serem usados no script seguinte
write_delim(osm_ids %>% select(osm_id = osm_way_id, infra_ciclo),
sprintf('%s/tmp_infra_ciclo_%s_revisada.csv', pasta_aoprv_alter, ano),
delim = ';')
# Gravar resultados para serem usados no script seguinte
write_delim(osm_ids %>% select(osm_id = osm_way_id, infra_ciclo) %>% distinct(),
sprintf('%s/tmp_infra_ciclo_%s_revisada.csv', pasta_aoprv_alter, ano),
delim = ';')
gc()
# carregar bibliotecas
library('tidyverse')
library('tidylog')
library('sf')
# Definir ano de análise e limite máximo de tempo
ano1 <- '2019'; ano2 <- '2028'; tempo_max <- '15'
# Qual solução usar? A primeira considera população de interesse maior do que as
# matrículas disponíveis; a segunda ajusta a população para caber nas matrículas
versao_solucao <- 2
# Estrutura de pastas e arquivos
pasta_dados       <- "../../yellow_dados"
dados_originais   <- sprintf("%s/00_dados_originais", pasta_dados)
pasta_ipea        <- sprintf("%s/IPEA", dados_originais)
pasta_osm_sp     <- sprintf("%s/02_osm_simplificado_sp", pasta_dados)
pasta_aop_rev     <- sprintf("%s/12_aop_revisitado", pasta_dados)
pasta_aoprv_alter <- sprintf("%s/03_alternatives_2019_2028", pasta_aop_rev)
pasta_aop_optimum <- sprintf("%s/13_aop_optimum", pasta_dados)
pasta_opaop_dados <- sprintf("%s/02_dados_pop_mat", pasta_aop_optimum)
if (versao_solucao == 1) {
pasta_aop_lpsolve <- sprintf("%s/03_lpSolve1_pop_maior_que_mat", pasta_aop_optimum)
} else if (versao_solucao == 2) {
pasta_aop_lpsolve <- sprintf("%s/04_lpSolve2_pop_ajustada", pasta_aop_optimum)
}
pasta_opaop_ano1  <- sprintf("%s/%s", pasta_aop_lpsolve, ano1)
pasta_opaop_ano2  <- sprintf("%s/%s", pasta_aop_lpsolve, ano2)
# IPEA - Shape de grid hexagonal (resolução 9)
hexagonos <- sprintf('%s/aop_hex_grid_v2.gpkg', pasta_ipea)
hexagonos <- read_sf(hexagonos) %>% filter(abbrev_muni == 'spo') %>% select(id_hex)
head(hexagonos)
# Demanda: quantidade de pessoas por hexágono
pop <- sprintf('%s/hex_grid_sp_res09_dados_censo_por_hexagono.csv', pasta_opaop_dados)
pop <- read_delim(pop, delim = ';', col_types = cols(.default = "c"))
# pop %>% filter(!id_hex %in% hex_sp$id_hex)
pop <- pop %>% mutate_at(2:ncol(.), as.numeric)
# Garantir que haja população
pop <- pop %>% filter(pessoas_15_17_hex > 0)
pop <- pop %>% select(id_hex, pop_15_17 = pessoas_15_17_hex)
# Checar se algum id ficou duplicado por qualquer motivo
# pop %>% group_by(orig) %>% tally() %>% filter(n > 1) %>% nrow()
head(pop)
# Oferta: quantidade de matrículas por hexágono
mat <- sprintf('%s/matriculas_censo_escolar_2019_por_hexagono.csv', pasta_opaop_dados)
mat <- read_delim(mat, delim = ';', col_types = cols(.default = "c"))
# mat %>% filter(!id_hex %in% hex_sp$id_hex)
mat <- mat %>% mutate_at(2:ncol(.), as.numeric)
# Garantir que haja matrículas
mat <- mat %>% filter(matriculas_idades_15_17 > 0)
# Checar se algum id ficou duplicado por qualquer motivo
# mat %>% group_by(id_hex) %>% tally() %>% filter(n > 1) %>% nrow()
mat <- mat %>% select(id_hex, mat_15_17 = matriculas_idades_15_17)
head(mat)
# Ajustar população proporcional ao número de matrículas existentes
proporcao_pop_mat <- sum(pop$pop_15_17) / sum(mat$mat_15_17)
pop <- pop %>% mutate(pop_prop_15_17 = round(pop_15_17 / proporcao_pop_mat))
# A nova população de interesse será agora a população reduzida proporcionalmente
head(pop)
# Juntar população e matrículas aos hexágonos
hex_pop_op <-
hexagonos %>%
st_drop_geometry() %>%
left_join(mat, by = 'id_hex') %>%
left_join(pop, by = 'id_hex') %>%
replace(is.na(.), 0)
head(hex_pop_op)
# Resultados por hexágono do lpSolver para o ano 1
hex_resultados_1 <- sprintf('%s/07_resultados_por_hexagono_%s_res09_%smin.csv', pasta_opaop_ano1, ano1, tempo_max)
hex_resultados_1 <- read_delim(hex_resultados_1, delim = ';', col_types = 'cciddii')
hex_resultados_1 <- hex_resultados_1 %>% rename(hexclas_19 = class_hex_orig,
vgs_ok_19  = viagens_a_tempo,
vgs_nok_19 = viagens_fora_tempo,
vgs_tot_19 = tot_viagens,
ext_cic_19 = ext_ciclo_tot_m,
perccic_19 = perc_part)
head(hex_resultados_1)
# Juntar aos resultados também as origens impossíveis
orig_impossiveis_1 <- sprintf('%s/06_lpsolve_hexagonos_origens_impossiveis_%s_%smin.gpkg', pasta_opaop_ano1, ano1, tempo_max)
orig_impossiveis_1 <- read_sf(orig_impossiveis_1) %>% st_drop_geometry() %>% select(orig = id_hex)
orig_impossiveis_1 <- orig_impossiveis_1 %>% mutate(hexclas_19 = 'hex origem impossivel',
vgs_ok_19  = as.numeric(NA),
vgs_nok_19 = as.numeric(NA),
vgs_tot_19 = as.numeric(NA),
ext_cic_19 = as.numeric(NA),
perccic_19 = as.numeric(NA))
hex_resultados_1 <- hex_resultados_1 %>% rbind(orig_impossiveis_1) %>% arrange(orig)
head(hex_resultados_1)
# Resultados por hexágono do lpSolver para o ano 2
hex_resultados_2 <- sprintf('%s/07_resultados_por_hexagono_%s_res09_%smin.csv', pasta_opaop_ano2, ano2, tempo_max)
hex_resultados_2 <- read_delim(hex_resultados_2, delim = ';', col_types = 'cciddii')
hex_resultados_2 <- hex_resultados_2 %>% rename(hexclas_28 = class_hex_orig,
vgs_ok_28  = viagens_a_tempo,
vgs_nok_28 = viagens_fora_tempo,
vgs_tot_28 = tot_viagens,
ext_cic_28 = ext_ciclo_tot_m,
perccic_28 = perc_part)
head(hex_resultados_2)
# Juntar aos resultados também as origens impossíveis
orig_impossiveis_2 <- sprintf('%s/06_lpsolve_hexagonos_origens_impossiveis_%s_%smin.gpkg', pasta_opaop_ano2, ano2, tempo_max)
orig_impossiveis_2 <- read_sf(orig_impossiveis_2) %>% st_drop_geometry() %>% select(orig = id_hex)
orig_impossiveis_2 <- orig_impossiveis_2 %>% mutate(hexclas_28 = 'hex origem impossivel',
vgs_ok_28  = as.numeric(NA),
vgs_nok_28 = as.numeric(NA),
vgs_tot_28 = as.numeric(NA),
ext_cic_28 = as.numeric(NA),
perccic_28 = as.numeric(NA))
hex_resultados_2 <- hex_resultados_2 %>% rbind(orig_impossiveis_2) %>% arrange(orig)
head(hex_resultados_2)
sample_n(hex_resultados_2, 20)
# Juntar resultados na grade completa de hexágonos
hex_resultados <-
hex_pop_op %>%
left_join(hex_resultados_1, by = c('id_hex' = 'orig')) %>%
left_join(hex_resultados_2, by = c('id_hex' = 'orig')) %>%
# Demarcar hexágonos sem população ou matrícula
mutate(hexclas_19 = ifelse(is.na(hexclas_19), 'hexag sem pop ou mat', hexclas_19),
hexclas_28 = ifelse(is.na(hexclas_28), 'hexag sem pop ou mat', hexclas_28)) %>%
# Quais as diferenças de viagens feitas dentro do tempo e extensão percorrida
# em infraestrutura cicloviária dessas mesmas viagens entre os dois cenários?
mutate(dif_vgs_ok = vgs_ok_28 - vgs_ok_19,
dif_cic_ok = ext_cic_28 - ext_cic_19)
# Juntar resultados ao shapefile de hexágonos
hexagonos <-
hexagonos %>%
left_join(hex_resultados, by = 'id_hex') %>%
relocate(c(perccic_19, perccic_28, geom), .after = last_col())
hexagonos
# Gravar resultados
out_hex <- sprintf('%s/hexagonos_sp_resultados_metodo_%s_res09_2019_2028.gpkg', pasta_aop_lpsolve, versao_solucao)
st_write(hexagonos, out_hex, driver = 'GPKG', append = FALSE, delete_layer = TRUE)
# Abrir cópia do viário de SP com osm_ids
viario_sp <- read_sf(sprintf('%s/sao_paulo_osm_filtrado.gpkg', pasta_osm_sp))
viario_sp <- viario_sp %>% select(osm_id) %>% st_transform(31983)
viario_sp <- viario_sp %>% mutate(ext = round(st_length(.), 4))
head(viario_sp)
# Infraestrutura cicloviária ano 1
ciclo_19 <- sprintf('%s/tmp_infra_ciclo_%s.csv', pasta_aoprv_alter, ano1)
ciclo_19 <- read_delim(ciclo_19, delim = ';', col_types = 'cc')
ciclo_19 <- ciclo_19 %>% rename(infra_ciclo_19 = infra_ciclo)
head(ciclo_19)
# Infraestrutura cicloviária ano 2
# # ATENÇÃO: Para a rede 2028, alguns osm_ids constantes no arquivo original
# tmp_infra_ciclo_%s.csv estão marcados como pertencentes à rede de referência,
# mas na verdade possuem só um trecho que de fato tem estrutura cicloviária.
# Isso foi percebido no momento do script 13.09 e um aviso foi colocado no
# script 12.14 e no script 12.12, que é o que gera o arquivo. A correção se deu
# no script 13.09, que gerou o  arquivo revisado tmp_infra_ciclo_%s_revisada.csv.
# Caso a correção seja implementada no 12.12, apagar esse aviso e voltar a
# referência para a primeira linha abaixo, em vez da segunda:
# ciclo_28 <- sprintf('%s/tmp_infra_ciclo_%s.csv', pasta_aoprv_alter, ano2)
ciclo_28 <- sprintf('%s/tmp_infra_ciclo_%s_revisada.csv', pasta_aoprv_alter, ano2)
ciclo_28 <- read_delim(ciclo_28, delim = ';', col_types = 'cc')
ciclo_28 <- ciclo_28 %>% rename(infra_ciclo_28 = infra_ciclo)
head(ciclo_28)
# Resultados por osm_id do lpSolver para o ano 1
viario_resultados_1 <- sprintf('%s/08_resultados_por_osmid_%s_res09_%smin.csv', pasta_opaop_ano1, ano1, tempo_max)
viario_resultados_1 <- read_delim(viario_resultados_1, delim = ';', col_types = 'cidd')
viario_resultados_1 <- viario_resultados_1 %>% rename(vgs_19  = viagens_tot,
cic_19  = ext_ciclo_tot_m,
perc_19 = perc_part)
head(viario_resultados_1)
# Resultados por hexágono do lpSolver para o ano 2
viario_resultados_2 <- sprintf('%s/08_resultados_por_osmid_%s_res09_%smin.csv', pasta_opaop_ano2, ano2, tempo_max)
viario_resultados_2 <- read_delim(viario_resultados_2, delim = ';', col_types = 'cidd')
viario_resultados_2 <- viario_resultados_2 %>% rename(vgs_28  = viagens_tot,
cic_28  = ext_ciclo_tot_m,
perc_28 = perc_part)
head(viario_resultados_2)
# Juntar resultados ao shapefile de viário
viario_sp <-
viario_sp %>%
left_join(viario_resultados_1, by = c('osm_id' = 'osm_way_id')) %>%
left_join(viario_resultados_2, by = c('osm_id' = 'osm_way_id')) %>%
mutate(across(everything(), ~ replace_na(.x, 0))) %>%
mutate(dif_vgs = vgs_28 - vgs_19,
dif_cic = cic_28 - cic_19) %>%
left_join(ciclo_19, by = 'osm_id') %>%
left_join(ciclo_28, by = 'osm_id') %>%
relocate(c(perc_19, perc_28, geom), .after = last_col())
head(viario_sp)
# Gravar resultados
out_viario <- sprintf('%s/viario_osm_sp_resultados_metodo_%s_res09_2019_2028.gpkg', pasta_aop_lpsolve, versao_solucao)
st_write(viario_sp, out_viario, driver = 'GPKG', append = FALSE)
# 4.511.118 metros de infra ciclo em 2028
infra_ciclo_2028 <- viario_sp %>% filter(!is.na(infra_ciclo_28)) %>% st_drop_geometry() %>% select(ext) %>% sum()
infra_ciclo_2028
# 636.401,5 metros de infra ciclo em 2019
infra_ciclo_2019 <- viario_sp %>% filter(!is.na(infra_ciclo_19)) %>% st_drop_geometry() %>% select(ext) %>% sum()
infra_ciclo_2019
infra_ciclo_2028 - infra_ciclo_2019
# dif_cic > 15000 = 878.760 m
# dif_cic >  5000 = 1.419.248 m
viario_sp %>% filter(dif_cic > 5000) %>% st_drop_geometry() %>% select(ext) %>% sum()
1800 * 636401 / 474
(1800 * 636401 / 474) - 636401
((1800 * 636401 / 474) - 636401) / 2
viario_sp %>% filter(dif_cic > 15000) %>% st_drop_geometry() %>% select(ext) %>% sum()
((1800 * 636401 / 474) - 636401) / 2
# dif_cic >  5000 = 1.303.798,00 m
viario_sp %>% filter(dif_cic > 5000) %>% st_drop_geometry() %>% select(ext) %>% sum()
pasta_graphhopper <- sprintf("%s/07_graphhopper", pasta_dados)
# Abrir shape com a marcação da rede cicloviária de referência
ciclo_futura <- sprintf('%s/sao_paulo_osm_filtrado_com_qgis_id_redes_cicloviarias_2019_2028.gpkg', pasta_graphhopper)
ciclo_futura <- read_sf(ciclo_futura) %>% st_drop_geometry()
ciclo_futura %>% filter(osm_id == '94577982')
ciclo_futura %>% filter(osm_id == '617088820')
ciclo_futura %>% filter(osm_id == '52110595')
ciclo_futura %>%
filter(osm_id == '52110595') %>%
# Tudo o que for NA vai ser marcado como 'sem rede', enquanto as redes 2019 e
# de referência vão ser marcadas ambas como de referência
mutate(rede = ifelse(is.na(rede_cicloviaria), 'sem rede', 'referencia')) %>%
group_by(osm_id, rede) %>%
summarise(ext = sum(length_m)) %>%
mutate(perc = ext / sum(ext) * 100)
ciclo_futura %>%
filter(osm_id == '855758834')
ciclo_futura %>%
filter(osm_id == '522976264')
viario_sp %>% filter(dif_cic > 15000) %>% mapview()
viario_sp
head(hex_resultados_1)
hex_resultados_1 %>% filter(hexclas_19 == 'hex origem impossivel')
# Quanto da rede temos que priorizar na visualização do QGIS?
viario_sp %>% filter(dif_cic > 15000) %>% st_drop_geometry() %>% select(ext) %>% sum()
viario_sp
viario_sp %>% filter(dif_cic >= 15000 & is.na(infra_ciclo_19)) %>% st_drop_geometry() %>% select(ext) %>% sum()
774190.3/1780312
gc()
# carregar bibliotecas
library('tidyverse')
library('tidylog')
# Definir ano de análise e limite máximo de tempo
# ano <- '2019'; tempo_max <- '15'
ano <- '2028'; tempo_max <- '15'
# Qual solução usar? A primeira considera população de interesse maior do que as
# matrículas disponíveis; a segunda ajusta a população para caber nas matrículas
versao_solucao <- 2
# Estrutura de pastas e arquivos
pasta_dados       <- "../../yellow_dados"
pasta_graphhopper <- sprintf("%s/07_graphhopper", pasta_dados)
pasta_aop_rev     <- sprintf("%s/12_aop_revisitado", pasta_dados)
pasta_aoprv_alter <- sprintf("%s/03_alternatives_2019_2028", pasta_aop_rev)
pasta_aop_optimum <- sprintf("%s/13_aop_optimum", pasta_dados)
pasta_opaop_ttmat <- sprintf("%s/01_ttmatrix", pasta_aop_optimum, ano)
if (versao_solucao == 1) {
pasta_aop_lpsolve <- sprintf("%s/03_lpSolve1_pop_maior_que_mat", pasta_aop_optimum)
} else if (versao_solucao == 2) {
pasta_aop_lpsolve <- sprintf("%s/04_lpSolve2_pop_ajustada", pasta_aop_optimum)
}
pasta_opaop_ano   <- sprintf("%s/%s", pasta_aop_lpsolve, ano)
rm(versao_solucao)
# Origens, destinos e quantidade de viagens
ods_vgs <- sprintf('%s/01_lpsolve_resultados_viagens_por_par_OD_%s_%smin.csv', pasta_opaop_ano, ano, tempo_max)
ods_vgs <- read_delim(ods_vgs, delim = ';', col_types = 'ccid')
# ods_vgs %>% filter(!is.na(time)) %>% select(orig, dest) %>% distinct() # 10.237
head(ods_vgs)
# Osm_ids que faziam parte da ttmatrix utilizada
osm_ids <- sprintf('%s/ttmatrix_osmids_%s_res09_%smin.csv', pasta_opaop_ttmat, ano, tempo_max)
osm_ids <- read_delim(osm_ids, delim = ';', col_types = 'cccd')
# osm_ids %>% select(orig, dest) %>% distinct() # 2019 - 245.187
head(osm_ids)
# Desmembrar coluna hex_id_alt em origem, destino e número da alternativa da rota
osm_ids <-
osm_ids %>%
mutate(hex_id_alt = str_replace(hex_id_alt,
'^([a-z0-9]{6})-([a-z0-9]{6})-([0-9])',
'89a81\\1ffff-89a81\\2ffff-\\3')) %>%
separate(hex_id_alt, into = c('orig', 'dest', 'alt'), sep = '-', remove = TRUE)
head(osm_ids)
# No script 12.12, fizemos um filtro da rede futura que puxou osm_ids que têm
# pequenas partes marcadas como rede de referência quando o restante desses
# mesmos osm_ids não possuem rede cicloviária. Um exemplo é o osm_id 264984110,
# que tem 8,06 metros de rede de referência dentre os seus 818,49 metros de
# viário. Vamos corrigir essa classificação aqui.
if (ano == '2028') {
# Abrir shape com a marcação da rede cicloviária de referência
ciclo_futura <- sprintf('%s/sao_paulo_osm_filtrado_com_qgis_id_redes_cicloviarias_2019_2028.gpkg', pasta_graphhopper)
ciclo_futura <- read_sf(ciclo_futura) %>% st_drop_geometry()
# # Redes: '2019', 'referencia', 'NA'
# ciclo_futura %>% filter(osm_id == '264984110')
# ciclo_futura %>% select(rede_cicloviaria) %>% distinct()
# Puxar osm_ids com pelo menos 50% de extensão de rede cicloviária
ciclo_futura <-
ciclo_futura %>%
# filter(osm_id == '264984110') %>%
# Tudo o que for NA vai ser marcado como 'sem rede', enquanto as redes 2019 e
# de referência vão ser marcadas ambas como de referência
mutate(rede = ifelse(is.na(rede_cicloviaria), 'sem rede', 'referencia')) %>%
group_by(osm_id, rede) %>%
summarise(ext = sum(length_m)) %>%
mutate(perc = ext / sum(ext) * 100) %>%
ungroup() %>%
# Manter somente os osm_ids com mais do que 50% de extensão com rede cicloviária
filter(rede == 'referencia' & perc > 50)
# Corrigir: nos osm_ids com infra cicloviária calculada percorrida pelo routing,
# tudo o que não estiver na rede de referência (2019 + 2028) e que tenha pelo
# menos x% de extensão com reder cicloviária, vai ser remarcado
osm_ids <-
osm_ids %>%
mutate(infra_ciclo = ifelse(osm_way_id %in% ciclo_futura$osm_id, infra_ciclo, as.character(NA))) %>%
filter(!is.na(infra_ciclo))
ods_vgs %>%
# Juntar quantidade de viagens para cada par OD
left_join(osm_ids, by = c('orig', 'dest'))
)
ods_vgs
osm_ids
ods_vgs %>%
# Juntar quantidade de viagens para cada par OD
left_join(osm_ids, by = c('orig', 'dest')) %>%
# Queremos somente os osm_id em que há infra cicloviária
filter(!is.na(osm_way_id))
# Visão por infraestrutura cicloviária utilizada: quanto de distância (em metros)
# foi percorrido em cada osm_id em determinado ano base?
osm_id_resultados <-
ods_vgs %>%
# Juntar quantidade de viagens para cada par OD
left_join(osm_ids, by = c('orig', 'dest')) %>%
# Queremos somente os osm_id em que há infra cicloviária
filter(!is.na(osm_way_id)) %>%
# Substituir NAs por zero para viagens que não passaram por infra_ciclo
mutate(ext_percorrida = ifelse(is.na(ext_percorrida), 0, ext_percorrida))
ods_resultados
ciclo_od
osm_id_resultados
osm_id_resultados %>%
filter(!is.na(time))
ods_vgs
ods_vgs %>% filter(is.na(time))
osm_id_resultados %>% filter(orig == '89a81000043ffff' & dest == '89a8100dd0fffff')
ods_vgs %>%
# Juntar quantidade de viagens para cada par OD
left_join(osm_ids, by = c('orig', 'dest')) %>%
# Queremos somente os osm_id em que há infra cicloviária
filter(orig == '89a81000043ffff' & dest == '89a8100dd0fffff')
ods_vgs %>%
# Juntar quantidade de viagens para cada par OD
left_join(osm_ids, by = c('orig', 'dest')) %>%
# Queremos somente os osm_id em que há infra cicloviária
# filter(orig == '89a81000043ffff' & dest == '89a8100dd0fffff')
# filter(!is.na(osm_way_id)) %>%
filter(!is.na(time)) %>% sample_n(20)
# carregar bibliotecas
library('tidyverse')
library('tidylog')
library('lpSolve')
library('sf')
library('mapview')
options(scipen = 999)
# Definir ano de análise e limite máximo de tempo
ano <- '2019'; tempo_max <- '15'
# Estrutura de pastas e arquivos
pasta_dados       <- "../../yellow_dados"
pasta_aop_rev     <- sprintf("%s/12_aop_revisitado", pasta_dados)
pasta_aoprv_alter <- sprintf("%s/03_alternatives_2019_2028", pasta_aop_rev)
pasta_aop_optimum <- sprintf("%s/13_aop_optimum", pasta_dados)
pasta_opaop_ttmat <- sprintf("%s/01_ttmatrix", pasta_aop_optimum, ano)
pasta_opaop_dados <- sprintf("%s/02_dados_pop_mat", pasta_aop_optimum)
pasta_aop_lpsolve <- sprintf("%s/04_lpSolve2_pop_ajustada", pasta_aop_optimum)
pasta_opaop_ano   <- sprintf("%s/%s", pasta_aop_lpsolve, ano)
dir.create(pasta_opaop_ano, recursive = TRUE, showWarnings = FALSE)
# Hexágonos que possuem oportunidades e/ou população, para checagem
hex_dados_popop <- sprintf('%s/tmp_sao_paulo_hexagonos_populacao_oportunidades.gpkg', pasta_aoprv_alter)
hex_dados_popop <- read_sf(hex_dados_popop)
# Demanda: quantidade de pessoas por hexágono
pop <- sprintf('%s/hex_grid_sp_res09_dados_censo_por_hexagono.csv', pasta_opaop_dados)
pop <- read_delim(pop, delim = ';', col_types = cols(.default = "c"))
pop <- pop %>% mutate_at(2:ncol(.), as.numeric)
pop <- pop %>% select(orig = id_hex, pop = pessoas_15_17_hex)
# Checar se algum id ficou duplicado por qualquer motivo
# pop %>% group_by(orig) %>% tally() %>% filter(n > 1) %>% nrow()
head(pop)
# Oferta: quantidade de matrículas por hexágono
mat <- sprintf('%s/matriculas_censo_escolar_2019_por_hexagono.csv', pasta_opaop_dados)
mat <- read_delim(mat, delim = ';', col_types = cols(.default = "c"))
mat <- mat %>% mutate_at(2:ncol(.), as.numeric)
mat <- mat %>% select(dest = id_hex, mat = matriculas_idades_15_17)
# Checar se algum id ficou duplicado por qualquer motivo
# mat %>% group_by(dest) %>% tally() %>% filter(n > 1) %>% nrow()
head(mat)
# Neste caso, temos uma demanda de população MAIOR do que a oferta de matrículas
print(sprintf('População: %s; Matrículas: %s (Diferença: %s)', sum(pop$pop), sum(mat$mat), sum(pop$pop) - sum(mat$mat)))
# carregar bibliotecas
source('fun/setup.R')
# Estrutura de pastas
pasta_dados        <- "../../yellow_dados"
pasta_modelos      <- sprintf('%s/06_bases_para_modelo', pasta_dados)
pasta_base_modelo  <- sprintf('%s/C_base_para_modelo', pasta_modelos)
# Abrir arquivos processados
# base_modelo <- sprintf('%s/yellow_base_para_modelo.csv', pasta_base_modelo)
base_modelo <- sprintf('%s/yellow_base_para_modelo_3ptos_50vgs.csv', pasta_base_modelo)
base_modelo <- read_delim(base_modelo, delim = ';', col_types = 'ccccdddddccdiccdccdddccccccccccccc')
head(base_modelo)
base_modelo <-
base_modelo %>%
mutate(
inicio_fim = factor(inicio_fim, levels = c('meio', 'início', 'final')),
cat_dist_total = factor(cat_dist_total, levels = c('media', 'acima_media', 'longa', 'muito_longa', 'curta')),
cat_dist_trecho = factor(cat_dist_trecho, levels = c('medio', 'acima_media', 'grande', 'muito_grande', 'curto')),
cat_grad   = factor(cat_grad,   levels = c('plano', 'desc_lev', 'desc_med', 'desc_for', 'desc_ver', 'subi_lev', 'subi_med', 'subi_for', 'subi_ver')),
# cat_grad_prev   = factor(cat_grad_prev,   levels = c('plano', 'desc_lev', 'desc_med', 'desc_for', 'desc_ver', 'subi_lev', 'subi_med', 'subi_for', 'subi_ver'))
class_via    = factor(class_via,   levels = c('local', 'coletora', 'arterial', 'vtr', 'ciclo_expressa', 'ped_serv')),
# class_viaosm = factor(class_via,   levels = c('local', 'coletora', 'arterial', 'vtr', 'ciclo_expressa', 'ped_serv')),
infra_ciclo  = factor(infra_ciclo, levels = c('sem_infra_ciclo', 'ciclofaixa', 'ciclovia')),
semaforos    = factor(semaforos, levels = c('sem_semaforos', 'inicio', 'fim', 'inicio_fim')),
via_restr    = factor(via_restr,   levels = c('via_comum', 'via_restrita')),
osm_oneway   = factor(osm_oneway, levels = c('yes', 'no')),
contramao    = factor(contramao, levels = c('não', 'sim')),
dia_util     = factor(dia_util,    levels = c('util', 'desc')),
cat_fx_hora  = factor(cat_fx_hora, levels = c('vale', 'pico_manha', 'pico_tarde', 'madrugada')),
cat_vg_loop  = factor(vg_loop, levels = c('não', 'sim')),
cat_vg_exper = factor(vg_exper, levels = c('não', 'sim')),
cat_vg_conm  = factor(vg_contramao, levels = c('não', 'sim')),
cat_vg_parq  = factor(vg_parques, levels = c('não', 'sim')),
cat_curv     = factor(cat_curv, levels = c('00 a 25 graus', '25 a 45 graus', '45 a 90 graus', 'acima de 90 graus')),
)
estatisticas_descritivas <- function(var) {
# Descrição das variáveis categóricas - uma por vez
# https://uc-r.github.io/descriptives_categorical
# Tabela de frequências
table <- table(base_modelo %>% select({{var}}))
# Tabela com proporcional do todo
table2 <- prop.table(table)
# Junção das tabelas
out <- rbind(table, table2) %>% t() %>% as.data.frame() %>% mutate(table2 = round(table2 * 100, 2))
print(var)
print(out)
}
estatisticas_descritivas_vg <- function(var) {
# Descrição das variáveis categóricas - uma por vez, agrupado por viagem
# https://uc-r.github.io/descriptives_categorical
# https://dplyr.tidyverse.org/articles/programming.html
out <-
base_modelo %>%
select(trip_id, {{var}}) %>%
distinct() %>%
group_by(across(all_of({{var}}))) %>%
tally() %>%
mutate(prop = as.character(round(n / sum(n) * 100, 2)))
print(out)
}
desc_var <- c('inicio_fim', 'cat_grad', 'class_via', 'infra_ciclo', 'semaforos',
'via_restr', 'osm_oneway', 'contramao', 'cat_dist_total',
'cat_dist_trecho','cat_curv', 'dia_util',
'cat_fx_hora', 'cat_vg_loop', 'cat_vg_exper', 'cat_vg_conm',
'cat_vg_parq')
for (var in desc_var) { estatisticas_descritivas(var) }
desc_var_vg <- c('cat_dist_total', 'cat_vg_conm',
'cat_vg_loop', 'cat_vg_parq',  'cat_vg_exper')
for (var in desc_var_vg) { estatisticas_descritivas_vg(var) }
base_modelo %>% select(dist_total)
base_modelo
base_modelo %>% select(trip_id, dist_total) %>% distinct()
base_modelo %>% select(trip_id, dist_total) %>% distinct() %>% summary()
base_modelo %>% select(trip_id, dist_total) %>% distinct() %>% quantile(probs = seq(0.9, 1, 0.01), na.rm = TRUE)
base_modelo %>% select(trip_id, dist_total) %>% distinct() %>% select(dist_total) %>% quantile(probs = seq(0.9, 1, 0.01), na.rm = TRUE)
base_modelo %>% select(trip_id, dist_total) %>% distinct() %>% select(dist_total) %>% quantile(probs = seq(0.8, 1, 0.01), na.rm = TRUE)
base_modelo %>% select(trip_id, dist_total) %>% distinct() %>% select(dist_total) %>% quantile(probs = seq(0.8, 1, 0.005), na.rm = TRUE)
base_modelo %>% select(trip_id, dist_total) %>% distinct() %>% select(dist_total) %>% summary()
