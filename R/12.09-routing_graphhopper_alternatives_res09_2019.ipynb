{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "618c1496",
   "metadata": {},
   "source": [
    "Comando para rodar o GraphHopper no terminal - atenção para o PBF a ser carregado:\n",
    "\n",
    "**PBF da Rede 2019; custom model ajustado (LTS)**\n",
    "\n",
    "clear && cd /home/livre/Desktop/Base_GtsRegionais/GitLab/yellow_src/graphhopper/ && rm -rf graph-cache/ && java -Ddw.graphhopper.datareader.file=/home/livre/Desktop/Base_GtsRegionais/GitLab/yellow_dados/07_graphhopper/03_PBFs_SP_rede_2019/20220216_sao_paulo_edited_20230521_A_infraciclo_atual.osm.pbf -jar graphhopper/web/target/graphhopper-web-*.jar server graphhopper/config-example_LTS.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba818af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar bibliotecas\n",
    "suppressPackageStartupMessages(library('tidyverse'))\n",
    "suppressPackageStartupMessages(library('tidylog'))\n",
    "suppressPackageStartupMessages(library('httr'))\n",
    "suppressPackageStartupMessages(library('jsonlite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb2506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: future\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aplicar funcoes em paralelo\n",
    "library('future.apply')\n",
    "# Checando: Jupyter suporta multicore?\n",
    "future::supportsMulticore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3655d666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>system:</strong> 8"
      ],
      "text/latex": [
       "\\textbf{system:} 8"
      ],
      "text/markdown": [
       "**system:** 8"
      ],
      "text/plain": [
       "system \n",
       "     8 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/40536067/how-to-adjust-future-global-maxsize\n",
    "# For 850MB: 850*1024^2 = 891289600\n",
    "# For +1.3GB: 1500*1024^2 = 1572864000\n",
    "# options(future.globals.maxSize = 891289600)\n",
    "options(future.globals.maxSize = 5e6) # 5 MB\n",
    "options(future.globals.maxSize = 15*1024^2) # 15 MB\n",
    "parallelly::availableCores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a3b56a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>mc.cores:</strong> 6"
      ],
      "text/latex": [
       "\\textbf{mc.cores:} 6"
      ],
      "text/markdown": [
       "**mc.cores:** 6"
      ],
      "text/plain": [
       "mc.cores \n",
       "       6 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(parallelly.availableCores.methods = \"mc.cores\")\n",
    "options(mc.cores = 6)\n",
    "parallelly::availableCores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1148b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrutura de pastas\n",
    "pasta_ssd         <- \"/media/livre/SSD120GB/yellow\"\n",
    "pasta_dados       <- \"../../yellow_dados\"\n",
    "# dados_originais   <- sprintf(\"%s/00_dados_originais/IPEA\", pasta_dados)\n",
    "pasta_aop_rev     <- sprintf(\"%s/12_aop_revisitado\", pasta_dados)\n",
    "# pasta_aoprev_hex  <- sprintf(\"%s/01_hexagonos_26_vizinhos\", pasta_aop_rev)\n",
    "pasta_aoprv_alter <- sprintf(\"%s/03_alternatives_2019_2028\", pasta_aop_rev)\n",
    "pasta_ids_aopt_19 <- sprintf(\"%s/A_2019_osm_way_ids_aop\", pasta_ssd)\n",
    "pasta_rts_aopt_19 <- sprintf(\"%s/B_2019_rotas_modeladas_alternatives\", pasta_ssd)\n",
    "dir.create(pasta_ids_aopt_19, recursive = TRUE, showWarnings = FALSE)\n",
    "dir.create(pasta_rts_aopt_19, recursive = TRUE, showWarnings = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d7d9e0",
   "metadata": {},
   "source": [
    "# Método 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1b19cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Routing a partir de dois pontos com rotas alternativas (até 3 por par OD)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Faz query de routing no GraphHopper e retorna resultados principais em dataframe,\n",
    "# com rotas até 3 alternativas por par OD - aceita um dataframe de uma linha como\n",
    "# entrada\n",
    "gh_route_alt <- function(hex_id, route_options) {\n",
    "  # url <- 'http://localhost:8989/route/?point=-23.5314933121698%2C-46.634354542765&point=-23.5390199310058%2C-46.6376369484305&profile=bike&instructions=false&calc_points=true&details=average_speed'\n",
    "  # url <- ods_vgs %>% slice(1) %>% select(url) %>% pull()\n",
    "  # Estação Vila Madalena: -23.546258,-46.690898\n",
    "  # IME: -23.559007,-46.73208\n",
    "  # CCSP: -23.571498,-46.639806\n",
    "  \n",
    "  # df_line$url <- paste('http://localhost:8989/route/?point=', \n",
    "  # '-23.541504', '%2C', '-46.685779', '&point=', \n",
    "  # '-23.571498', '%2C', '-46.639806', route_options,\n",
    "  # sep = '')\n",
    "  \n",
    "  # hex_id <- '89a81046b2fffff-89a81044d8fffff'\n",
    "  # hex_id <- hex_com_vizinhos %>% head(1) %>% select(id) %>% pull()\n",
    "  df_line <- hex_com_vizinhos %>% filter(id == hex_id)\n",
    "  # Encurtar hex_id - todos aqui são '89a81' + 6 caracteres de dígito ou letra = 'ffff'\n",
    "  hex_id_short <- str_replace(hex_id, '^89a81([a-z0-9]{6})ffff-89a81([a-z0-9]{6})ffff', '\\\\1-\\\\2')\n",
    "  hex_id_base  <- str_sub(hex_id_short, 1, 6)\n",
    "  \n",
    "  # Fazer a GET de roteamento no Grahphopper\n",
    "  # print(df_line$url)\n",
    "  gh_response <- GET(df_line$url)\n",
    "  \n",
    "  # Mensagem tem que ser \"Success: (200) OK\"\n",
    "  if (http_status(gh_response)$message == 'Success: (200) OK') {\n",
    "    \n",
    "    # Resposta da query, já colapsada e transformada em dataframe\n",
    "    # Remover aviso de 'No encoding supplied: defaulting to UTF-8' na linha fromJSON()\n",
    "    suppressMessages(\n",
    "      response_text <- \n",
    "        # Ignorar aviso 'argument is not an atomic vector; coercing'\n",
    "        suppressWarnings(str_c(content(gh_response, 'text'), collapse = \", \")) %>% \n",
    "        # Concatenar toda a string de resultados\n",
    "        str_c(\"[\", ., \"]\") %>% \n",
    "        # Transformar em dataframe\n",
    "        fromJSON() %>% \n",
    "        as.data.frame()\n",
    "    )\n",
    "    \n",
    "    # Nos interessa a coluna de 'paths', como um novo dataframe\n",
    "    paths <- response_text$paths %>% as.data.frame()\n",
    "    \n",
    "    # Puxar osm_way_ids dos resultados de cada alternativa e gravar em pasta separada\n",
    "    for (i in seq(1, length(paths$details$osm_way_id))) {\n",
    "      # i <- 1\n",
    "      osm_ways <- paths$details$osm_way_id[i] %>% as.data.frame()\n",
    "      \n",
    "      if (nrow(osm_ways) > 0) {\n",
    "        # Manter somente osm_ids e inserir número da rota alternativa\n",
    "        osm_ways <- osm_ways %>% select(osm_way_id = X3) %>% mutate(hex_id = hex_id_short,\n",
    "                                                                    alt = i,\n",
    "                                                                    index = row_number(),\n",
    "                                                                    .before = 'osm_way_id')\n",
    "        # Gravar resultados agrupados por hex_id_short de origem\n",
    "        osm_way_out <- sprintf('%s/%s.csv', pasta_ids_aopt_19, hex_id_base)\n",
    "        if (file.exists(osm_way_out)) {\n",
    "          write_delim(osm_ways, osm_way_out, delim = ';', append = TRUE)\n",
    "        } else {\n",
    "          write_delim(osm_ways, osm_way_out, delim = ';', append = FALSE)\n",
    "        }\n",
    "        \n",
    "      } else {\n",
    "        # Se não há osm_way_ids, é porque os pontos estão muito próximos uns dos\n",
    "        # outros, mesmo que seja um osm_way_id diferente entre a origem e o \n",
    "        # destino. A distância e a velocidade calculadas vão ser zero também - \n",
    "        # pular este registro, que vai ser vazio\n",
    "        return(sprintf('Pulando: %s não tem osm_way_ids (provavelmente tem distância = 0)', hex_id))\n",
    "      }\n",
    "      \n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Isolar colunas de interesse\n",
    "    paths <- \n",
    "      paths %>% \n",
    "      # Calcular tempo em segundos e velocidade média\n",
    "      mutate(time = time / 1000,\n",
    "             speed = distance / time * 3.6) %>% \n",
    "      # Descartar colunas extras - a coluna poly é o shape da rota traçada\n",
    "      select(distance, weight, time, speed, poly = points)\n",
    "    \n",
    "    # Testar polyline:\n",
    "    # https://valhalla.github.io/demos/polyline/?unescape=true&polyline6=false#%0A\n",
    "    \n",
    "    # Adicionar colunas de informação vindas do dataframe original\n",
    "    paths <- \n",
    "      paths %>% \n",
    "      mutate(hex_id    = hex_id_short,\n",
    "             alt       = row_number(),\n",
    "             # id_hex.x  = df_line$id_hex_x,\n",
    "             # id_hex.y  = df_line$id_hex_y,\n",
    "             .before = 'distance') #%>% \n",
    "    # mutate(lon.x     = df_line$lon.x,\n",
    "    #        lat.x     = df_line$lat.x,\n",
    "    #        lon.y     = df_line$lon.y,\n",
    "    #        lat.y     = df_line$lat.y,\n",
    "    #        .after = 'poly')\n",
    "    \n",
    "  } else {\n",
    "    \n",
    "    # Se a query no GraphHopper não deu resultados, guardar como dataframe vazio\n",
    "    paths <- data.frame(hex_id    = hex_id_short,\n",
    "                        alt       = NA,\n",
    "                        # id_hex.x  = df_line$id_hex_x,\n",
    "                        # id_hex.y  = df_line$id_hex_y,\n",
    "                        distance  = NA,\n",
    "                        weight    = NA,\n",
    "                        time      = NA,\n",
    "                        speed     = NA,\n",
    "                        poly      = NA\n",
    "                        # lon.x     = df_line$lon.x,\n",
    "                        # lat.x     = df_line$lat.x,\n",
    "                        # lon.y     = df_line$lon.y,\n",
    "                        # lat.y     = df_line$lat.y\n",
    "    )\n",
    "    \n",
    "  }\n",
    "  \n",
    "  # Guardar resultados temporários agrupados por hex_id_short de origem\n",
    "  tmp_file <- sprintf('%s/%s_modalt.csv', pasta_rts_aopt_19, hex_id_base)\n",
    "  if (file.exists(tmp_file)) {\n",
    "    write_delim(paths, tmp_file, delim = ';', append = TRUE)\n",
    "  } else {\n",
    "    write_delim(paths, tmp_file, delim = ';', append = FALSE)\n",
    "  }\n",
    "  \n",
    "  # Guardar ids já processados em arquivo próprio\n",
    "  df_line <- df_line %>% select(id)\n",
    "  ids_processados <- sprintf('%s/tmp_00_ids_processados_2019.csv', pasta_ssd)\n",
    "\n",
    "  if (file.exists(ids_processados)) {\n",
    "    write_delim(df_line, ids_processados, delim = ';', append = TRUE)\n",
    "  } else {\n",
    "    write_delim(df_line, ids_processados, delim = ';', append = FALSE)\n",
    "  }\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc0e4ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "detach(\"package:tidylog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "353aee39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_114.csv\"\n",
      "[1] 12270\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_115.csv\"\n",
      "[1] 18033\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_116.csv\"\n",
      "[1] 21281\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_117.csv\"\n",
      "[1] 16758\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_118.csv\"\n",
      "[1] 22856\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_119.csv\"\n",
      "[1] 19895\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_120.csv\"\n",
      "[1] 22144\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_121.csv\"\n",
      "[1] 18935\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_122.csv\"\n",
      "[1] 18969\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_123.csv\"\n",
      "[1] 23492\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_124.csv\"\n",
      "[1] 19539\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_125.csv\"\n",
      "[1] 21879\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_126.csv\"\n",
      "[1] 20517\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_127.csv\"\n",
      "[1] 23232\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_128.csv\"\n",
      "[1] 19057\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_129.csv\"\n",
      "[1] 22252\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_130.csv\"\n",
      "[1] 21952\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_131.csv\"\n",
      "[1] 21780\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_132.csv\"\n",
      "[1] 20929\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_133.csv\"\n",
      "[1] 21238\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_134.csv\"\n",
      "[1] 20906\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_135.csv\"\n",
      "[1] 20431\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_136.csv\"\n",
      "[1] 23006\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_137.csv\"\n",
      "[1] 23390\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_138.csv\"\n",
      "[1] 23377\n",
      "[1] \"/media/livre/SSD120GB/yellow/tmp_base_para_routing_res09_26vizinhos_139.csv\"\n",
      "[1] 9893\n"
     ]
    }
   ],
   "source": [
    "# Arquivos a processar\n",
    "arqs <- list.files(pasta_ssd, pattern = '^tmp_base_para_routing_res09_26vizinhos_[0-9]{3}.csv', full.names = TRUE)\n",
    "# Arquivos já processados\n",
    "ids_processados <- sprintf('%s/tmp_00_ids_processados_2019.csv', pasta_ssd)\n",
    "\n",
    "for (arq in arqs) {\n",
    "  # arq <- arqs[1]\n",
    "  print(arq)\n",
    "  \n",
    "  # Abrir base para routing com 26 vizinhos, manter só id e url  \n",
    "  hex_com_vizinhos <- read_delim(arq, delim = ';', col_types = cols(.default = \"c\"))\n",
    "  \n",
    "  # Checar quais resultados já foram rodados - abrir lista, puxar ids e remover\n",
    "  # do dataframe hex_com_vizinhos se houver\n",
    "  # library('tidylog')\n",
    "  if (file.exists(ids_processados)) {\n",
    "    arqs_resultados <- read_delim(ids_processados, delim = ';', col_types = \"c\")\n",
    "    hex_com_vizinhos <- hex_com_vizinhos %>% filter(!id %in% arqs_resultados$hex_id)\n",
    "    rm(arqs_resultados)\n",
    "    print(nrow(hex_com_vizinhos))\n",
    "  }\n",
    "  \n",
    "  # Se arquivo já foi completamente processado, removê-lo e passar para o seguinte\n",
    "  if (nrow(hex_com_vizinhos) == 0) { \n",
    "    file.remove(arq) \n",
    "    next\n",
    "  }\n",
    "  \n",
    "  # Limpar memória\n",
    "  gc(T)\n",
    "  \n",
    "  # Criar ttmatrix a partir do GrahHopper - melhor rodar no Jupyter se for AOP;\n",
    "  # se forem só as rotas originais, é ok rodar no RStudio\n",
    "  # for (id in hex_com_vizinhos$id) { gh_route_alt(id, route_options = route_options) }\n",
    "  # Rodar função para todos os arquivos- multi thread (Jupyter)\n",
    "  (start = Sys.time())\n",
    "  future::plan(future::multicore)\n",
    "  invisible(future.apply::future_lapply(X   = hex_com_vizinhos$id,\n",
    "                                        FUN = gh_route_alt,\n",
    "                                        future.seed = TRUE))\n",
    "  Sys.time()\n",
    "  Sys.time() - start\n",
    "  \n",
    "  # Remover arquivo inteiramente processado\n",
    "  file.remove(arq) \n",
    "  \n",
    "  # Limpar memória\n",
    "  rm(hex_com_vizinhos)  \n",
    "  gc(T)\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08073f36",
   "metadata": {},
   "source": [
    "# Método 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83195731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------------------------------------------------------------------------\n",
    "# # Routing a partir de dois pontos com rotas alternativas (até 3 por par OD)\n",
    "# # ------------------------------------------------------------------------------\n",
    "\n",
    "# # Faz query de routing no GraphHopper e retorna resultados principais em dataframe,\n",
    "# # com rotas até 3 alternativas por par OD - aceita um dataframe de uma linha como\n",
    "# # entrada\n",
    "# gh_route_alt <- function(hex_id, route_options) {\n",
    "#   # url <- 'http://localhost:8989/route/?point=-23.5314933121698%2C-46.634354542765&point=-23.5390199310058%2C-46.6376369484305&profile=bike&instructions=false&calc_points=true&details=average_speed'\n",
    "#   # url <- ods_vgs %>% slice(1) %>% select(url) %>% pull()\n",
    "#   # Estação Vila Madalena: -23.546258,-46.690898\n",
    "#   # IME: -23.559007,-46.73208\n",
    "#   # CCSP: -23.571498,-46.639806\n",
    "  \n",
    "#   # df_line$url <- paste('http://localhost:8989/route/?point=', \n",
    "#   # '-23.541504', '%2C', '-46.685779', '&point=', \n",
    "#   # '-23.571498', '%2C', '-46.639806', route_options,\n",
    "#   # sep = '')\n",
    "  \n",
    "#   # hex_id <- '89a81046b2fffff-89a81044d8fffff'\n",
    "#   # hex_id <- hex_com_vizinhos %>% head(1) %>% select(id) %>% pull()\n",
    "#   df_line <- hex_com_vizinhos %>% filter(id == hex_id)\n",
    "  \n",
    "#   # Fazer a GET de roteamento no Grahphopper\n",
    "#   # print(df_line$url)\n",
    "#   gh_response <- GET(df_line$url)\n",
    "  \n",
    "#   # Mensagem tem que ser \"Success: (200) OK\"\n",
    "#   if (http_status(gh_response)$message == 'Success: (200) OK') {\n",
    "    \n",
    "#     # Resposta da query, já colapsada e transformada em dataframe\n",
    "#     # Remover aviso de 'No encoding supplied: defaulting to UTF-8' na linha fromJSON()\n",
    "#     suppressMessages(\n",
    "#       response_text <- \n",
    "#         # Ignorar aviso 'argument is not an atomic vector; coercing'\n",
    "#         suppressWarnings(str_c(content(gh_response, 'text'), collapse = \", \")) %>% \n",
    "#         # Concatenar toda a string de resultados\n",
    "#         str_c(\"[\", ., \"]\") %>% \n",
    "#         # Transformar em dataframe\n",
    "#         fromJSON() %>% \n",
    "#         as.data.frame()\n",
    "#     )\n",
    "    \n",
    "#     # Nos interessa a coluna de 'paths', como um novo dataframe\n",
    "#     paths <- response_text$paths %>% as.data.frame()\n",
    "    \n",
    "#     # Puxar osm_way_ids dos resultados de cada alternativa e gravar em pasta separada\n",
    "#     for (i in seq(1, length(paths$details$osm_way_id))) {\n",
    "#       # i <- 1\n",
    "#       osm_ways <- paths$details$osm_way_id[i] %>% as.data.frame()\n",
    "      \n",
    "#       if (nrow(osm_ways) > 0) {\n",
    "#         # Manter somente osm_ids e inserir número da rota alternativa\n",
    "#         osm_ways <- osm_ways %>% select(osm_way_id = X3) %>% mutate(alt = i,\n",
    "#                                                                     index = row_number(),\n",
    "#                                                                     .before = 'osm_way_id')\n",
    "#         # Gravar resultados\n",
    "#         osm_way_out <- sprintf('%s/%s.csv', pasta_ids_aopt_19, df_line$id)\n",
    "#         if (file.exists(osm_way_out)) {\n",
    "#           write_delim(osm_ways, osm_way_out, delim = ';', append = TRUE)\n",
    "#         } else {\n",
    "#           write_delim(osm_ways, osm_way_out, delim = ';', append = FALSE)\n",
    "#         }\n",
    "        \n",
    "#       } else {\n",
    "#         # Se não há osm_way_ids, é porque os pontos estão muito próximos uns dos\n",
    "#         # outros, mesmo que seja um osm_way_id diferente entre a origem e o \n",
    "#         # destino. A distância e a velocidade calculadas vão ser zero também - \n",
    "#         # pular este registro, que vai ser vazio\n",
    "#         return(sprintf('Pulando: %s não tem osm_way_ids (provavelmente tem distância = 0)', hex_id))\n",
    "#       }\n",
    "      \n",
    "#     }\n",
    "    \n",
    "    \n",
    "#     # Isolar colunas de interesse\n",
    "#     paths <- \n",
    "#       paths %>% \n",
    "#       # Calcular tempo em segundos e velocidade média\n",
    "#       mutate(time = time / 1000,\n",
    "#              speed = distance / time * 3.6) %>% \n",
    "#       # Descartar colunas extras - a coluna poly é o shape da rota traçada\n",
    "#       select(distance, weight, time, speed, poly = points)\n",
    "    \n",
    "#     # Testar polyline:\n",
    "#     # https://valhalla.github.io/demos/polyline/?unescape=true&polyline6=false#%0A\n",
    "    \n",
    "#     # Adicionar colunas de informação vindas do dataframe original\n",
    "#     paths <- \n",
    "#       paths %>% \n",
    "#       mutate(hex_id    = df_line$id,\n",
    "#              alt       = row_number(),\n",
    "#              # id_hex.x  = df_line$id_hex_x,\n",
    "#              # id_hex.y  = df_line$id_hex_y,\n",
    "#              .before = 'distance') #%>% \n",
    "#     # mutate(lon.x     = df_line$lon.x,\n",
    "#     #        lat.x     = df_line$lat.x,\n",
    "#     #        lon.y     = df_line$lon.y,\n",
    "#     #        lat.y     = df_line$lat.y,\n",
    "#     #        .after = 'poly')\n",
    "    \n",
    "#   } else {\n",
    "    \n",
    "#     # Se a query no GraphHopper não deu resultados, guardar como dataframe vazio\n",
    "#     paths <- data.frame(hex_id    = df_line$id,\n",
    "#                         alt       = NA,\n",
    "#                         # id_hex.x  = df_line$id_hex_x,\n",
    "#                         # id_hex.y  = df_line$id_hex_y,\n",
    "#                         distance  = NA,\n",
    "#                         weight    = NA,\n",
    "#                         time      = NA,\n",
    "#                         speed     = NA,\n",
    "#                         poly      = NA\n",
    "#                         # lon.x     = df_line$lon.x,\n",
    "#                         # lat.x     = df_line$lat.x,\n",
    "#                         # lon.y     = df_line$lon.y,\n",
    "#                         # lat.y     = df_line$lat.y\n",
    "#     )\n",
    "    \n",
    "#   }\n",
    "  \n",
    "#   # Guardar resultados temporários\n",
    "#   tmp_file <- sprintf('%s/%s_modalt.csv', pasta_rts_aopt_19, df_line$id)\n",
    "#   write_delim(paths, tmp_file, delim = ';')\n",
    "  \n",
    "#   # Guardar ids já processados em arquivo próprio\n",
    "#   df_line <- df_line %>% select(id)\n",
    "#   ids_processados <- sprintf('%s/tmp_00_ids_processados.csv', pasta_aoprv_alter)\n",
    "\n",
    "#   if (file.exists(ids_processados)) {\n",
    "#     write_delim(df_line, ids_processados, delim = ';', append = TRUE)\n",
    "#   } else {\n",
    "#     write_delim(df_line, ids_processados, delim = ';', append = FALSE)\n",
    "#   }\n",
    "  \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86601918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detach(\"package:tidylog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d216448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Arquivos a processar\n",
    "# arqs <- list.files(pasta_aoprv_alter, pattern = '^tmp_base_para_routing_res09_26vizinhos_[0-9]{3}.csv', full.names = TRUE)\n",
    "# # Arquivos já processados\n",
    "# ids_processados <- sprintf('%s/tmp_00_ids_processados.csv', pasta_aoprv_alter)\n",
    "\n",
    "# for (arq in arqs) {\n",
    "#   # arq <- arqs[1]\n",
    "#   print(arq)\n",
    "  \n",
    "#   # Abrir base para routing com 26 vizinhos, manter só id e url  \n",
    "#   hex_com_vizinhos <- read_delim(arq, delim = ';', col_types = cols(.default = \"c\"))\n",
    "  \n",
    "#   # Checar quais resultados já foram rodados - abrir lista, puxar ids e remover\n",
    "#   # do dataframe hex_com_vizinhos se houver\n",
    "#   # library('tidylog')\n",
    "#   if (file.exists(ids_processados)) {\n",
    "#     arqs_resultados <- read_delim(ids_processados, delim = ';', col_types = \"c\")\n",
    "#     hex_com_vizinhos <- hex_com_vizinhos %>% filter(!id %in% arqs_resultados$id)\n",
    "#     rm(arqs_resultados)\n",
    "#     nrow(hex_com_vizinhos)\n",
    "#   }\n",
    "  \n",
    "#   # Se arquivo já foi completamente processado, removê-lo e passar para o seguinte\n",
    "#   if (nrow(hex_com_vizinhos) == 0) { \n",
    "#     file.remove(arq) \n",
    "#     next\n",
    "#   }\n",
    "  \n",
    "#   # Limpar memória\n",
    "#   gc(T)\n",
    "  \n",
    "#   # Criar ttmatrix a partir do GrahHopper - melhor rodar no Jupyter se for AOP;\n",
    "#   # se forem só as rotas originais, é ok rodar no RStudio\n",
    "#   # for (id in hex_com_vizinhos$id) { gh_route_alt(id, route_options = route_options) }\n",
    "#   # Rodar função para todos os arquivos- multi thread (Jupyter)\n",
    "#   (start = Sys.time())\n",
    "#   future::plan(future::multicore)\n",
    "#   invisible(future.apply::future_lapply(X   = hex_com_vizinhos$id,\n",
    "#                                         FUN = gh_route_alt,\n",
    "#                                         future.seed = TRUE))\n",
    "#   Sys.time()\n",
    "#   Sys.time() - start\n",
    "  \n",
    "#   # Remover arquivo inteiramente processado\n",
    "#   file.remove(arq) \n",
    "  \n",
    "#   # Limpar memória\n",
    "#   rm(hex_com_vizinhos)  \n",
    "#   gc(T)\n",
    "  \n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342af264",
   "metadata": {},
   "source": [
    "# Método 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b09f05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------------------------------------------------------------------------\n",
    "# # Routing a partir de dois pontos com rotas alternativas (até 3 por par OD)\n",
    "# # ------------------------------------------------------------------------------\n",
    "\n",
    "# # Faz query de routing no GraphHopper e retorna resultados principais em dataframe,\n",
    "# # com rotas até 3 alternativas por par OD - aceita um dataframe de uma linha como\n",
    "# # entrada\n",
    "# gh_route_alt <- function(hex_id, route_options) {\n",
    "#   # url <- 'http://localhost:8989/route/?point=-23.5314933121698%2C-46.634354542765&point=-23.5390199310058%2C-46.6376369484305&profile=bike&instructions=false&calc_points=true&details=average_speed'\n",
    "#   # url <- ods_vgs %>% slice(1) %>% select(url) %>% pull()\n",
    "#   # Estação Vila Madalena: -23.546258,-46.690898\n",
    "#   # IME: -23.559007,-46.73208\n",
    "#   # CCSP: -23.571498,-46.639806\n",
    "  \n",
    "#   # df_line$url <- paste('http://localhost:8989/route/?point=', \n",
    "#   # '-23.541504', '%2C', '-46.685779', '&point=', \n",
    "#   # '-23.571498', '%2C', '-46.639806', route_options,\n",
    "#   # sep = '')\n",
    "  \n",
    "#   # hex_id <- '89a81046b2fffff-89a81044d8fffff'\n",
    "#   # hex_id <- hex_com_vizinhos %>% head(1) %>% select(id) %>% pull()\n",
    "#   df_line <- hex_com_vizinhos %>% filter(id == hex_id)\n",
    "  \n",
    "#   # Fazer a GET de roteamento no Grahphopper\n",
    "#   # print(df_line$url)\n",
    "#   gh_response <- GET(df_line$url)\n",
    "  \n",
    "#   # Mensagem tem que ser \"Success: (200) OK\"\n",
    "#   if (http_status(gh_response)$message == 'Success: (200) OK') {\n",
    "    \n",
    "#     # Resposta da query, já colapsada e transformada em dataframe\n",
    "#     # Remover aviso de 'No encoding supplied: defaulting to UTF-8' na linha fromJSON()\n",
    "#     suppressMessages(\n",
    "#       response_text <- \n",
    "#         # Ignorar aviso 'argument is not an atomic vector; coercing'\n",
    "#         suppressWarnings(str_c(content(gh_response, 'text'), collapse = \", \")) %>% \n",
    "#         # Concatenar toda a string de resultados\n",
    "#         str_c(\"[\", ., \"]\") %>% \n",
    "#         # Transformar em dataframe\n",
    "#         fromJSON() %>% \n",
    "#         as.data.frame()\n",
    "#     )\n",
    "    \n",
    "#     # Nos interessa a coluna de 'paths', como um novo dataframe\n",
    "#     paths <- response_text$paths %>% as.data.frame()\n",
    "    \n",
    "#     # Puxar osm_way_ids dos resultados de cada alternativa e gravar em pasta separada\n",
    "#     for (i in seq(1, length(paths$details$osm_way_id))) {\n",
    "#       # i <- 1\n",
    "#       osm_ways <- paths$details$osm_way_id[i] %>% as.data.frame()\n",
    "      \n",
    "#       if (nrow(osm_ways) > 0) {\n",
    "#         # TODO: Inserir número da rota alternativa aqui\n",
    "#         osm_ways <- osm_ways %>% mutate(index = row_number()) %>% select(index, osm_way_id = X3)\n",
    "        \n",
    "#         # Gravar resultados\n",
    "#         osm_way_out <- sprintf('%s/%s_%i.csv', pasta_ids_aopt_19, df_line$id, i)\n",
    "#         write_delim(osm_ways, osm_way_out, delim = ';')\n",
    "        \n",
    "#       } else {\n",
    "#         # Se não há osm_way_ids, é porque os pontos estão muito próximos uns dos\n",
    "#         # outros, mesmo que seja um osm_way_id diferente entre a origem e o \n",
    "#         # destino. A distância e a velocidade calculadas vão ser zero também - \n",
    "#         # pular este registro, que vai ser vazio\n",
    "#         return(sprintf('Pulando: %s não tem osm_way_ids (provavelmente tem distância = 0)', hex_id))\n",
    "#       }\n",
    "      \n",
    "#     }\n",
    "    \n",
    "    \n",
    "#     # Isolar colunas de interesse\n",
    "#     paths <- \n",
    "#       paths %>% \n",
    "#       # Calcular tempo em segundos e velocidade média\n",
    "#       mutate(time = time / 1000,\n",
    "#              speed = distance / time * 3.6) %>% \n",
    "#       # Descartar colunas extras - a coluna poly é o shape da rota traçada\n",
    "#       select(distance, weight, time, speed, poly = points)\n",
    "    \n",
    "#     # Testar polyline:\n",
    "#     # https://valhalla.github.io/demos/polyline/?unescape=true&polyline6=false#%0A\n",
    "    \n",
    "#     # Adicionar colunas de informação vindas do dataframe original\n",
    "#     paths <- \n",
    "#       paths %>% \n",
    "#       mutate(hex_id    = df_line$id,\n",
    "#              alt       = row_number(),\n",
    "#              # id_hex.x  = df_line$id_hex_x,\n",
    "#              # id_hex.y  = df_line$id_hex_y,\n",
    "#              .before = 'distance') #%>% \n",
    "#       # mutate(lon.x     = df_line$lon.x,\n",
    "#       #        lat.x     = df_line$lat.x,\n",
    "#       #        lon.y     = df_line$lon.y,\n",
    "#       #        lat.y     = df_line$lat.y,\n",
    "#       #        .after = 'poly')\n",
    "    \n",
    "#   } else {\n",
    "    \n",
    "#     # Se a query no GraphHopper não deu resultados, guardar como dataframe vazio\n",
    "#     paths <- data.frame(hex_id    = df_line$id,\n",
    "#                         alt       = NA,\n",
    "#                         # id_hex.x  = df_line$id_hex_x,\n",
    "#                         # id_hex.y  = df_line$id_hex_y,\n",
    "#                         distance  = NA,\n",
    "#                         weight    = NA,\n",
    "#                         time      = NA,\n",
    "#                         speed     = NA,\n",
    "#                         poly      = NA\n",
    "#                         # lon.x     = df_line$lon.x,\n",
    "#                         # lat.x     = df_line$lat.x,\n",
    "#                         # lon.y     = df_line$lon.y,\n",
    "#                         # lat.y     = df_line$lat.y\n",
    "#     )\n",
    "    \n",
    "#   }\n",
    "  \n",
    "#   # Guardar resultados temporários\n",
    "#   tmp_file <- sprintf('%s/%s_modalt.csv', pasta_rts_aopt_19, df_line$id)\n",
    "#   write_delim(paths, tmp_file, delim = ';')\n",
    "\n",
    "#   # Guardar ids já processados em arquivo próprio\n",
    "#   df_line <- df_line %>% select(id)\n",
    "#   ids_processados <- sprintf('%s/tmp_00_ids_processados.csv', pasta_aoprv_alter)\n",
    "  \n",
    "#   if (file.exists(ids_processados)) {\n",
    "#     write_delim(df_line, ids_processados, delim = ';', append = TRUE)\n",
    "#   } else if (!file.exists(ids_processados)) {\n",
    "#     write_delim(df_line, ids_processados, delim = ';', append = FALSE)\n",
    "#   }\n",
    "  \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88b7ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detach(\"package:tidylog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3427883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Arquivos a processar\n",
    "# arqs <- list.files(pasta_aoprv_alter, pattern = '^tmp_base_para_routing_res09_26vizinhos_[0-9]{3}.csv', full.names = TRUE)\n",
    "# # Arquivos já processados\n",
    "# ids_processados <- sprintf('%s/tmp_00_ids_processados.csv', pasta_aoprv_alter)\n",
    "\n",
    "# for (arq in arqs) {\n",
    "#   # arq <- arqs[1]\n",
    "#   print(arq)\n",
    "\n",
    "#   # Abrir base para routing com 26 vizinhos, manter só id e url  \n",
    "#   hex_com_vizinhos <- read_delim(arq, delim = ';', col_types = cols(.default = \"c\"))\n",
    "  \n",
    "#   # Checar quais resultados já foram rodados - abrir lista, puxar ids e remover\n",
    "#   # do dataframe hex_com_vizinhos se houver\n",
    "#   # library('tidylog')\n",
    "#   if (file.exists(ids_processados)) {\n",
    "#     arqs_resultados <- read_delim(ids_processados, delim = ';', col_types = \"c\")\n",
    "#     hex_com_vizinhos <- hex_com_vizinhos %>% filter(!id %in% arqs_resultados$id)\n",
    "#     rm(arqs_resultados)\n",
    "#     nrow(hex_com_vizinhos)\n",
    "#   }\n",
    "\n",
    "#   # Se arquivo já foi completamente processado, removê-lo e passar para o seguinte\n",
    "#   if (nrow(hex_com_vizinhos) == 0) { \n",
    "#       file.remove(arq) \n",
    "#       next\n",
    "#   }\n",
    "\n",
    "#   # Limpar memória\n",
    "#   gc(T)\n",
    "  \n",
    "#   # Criar ttmatrix a partir do GrahHopper - melhor rodar no Jupyter se for AOP;\n",
    "#   # se forem só as rotas originais, é ok rodar no RStudio\n",
    "#   # for (id in hex_com_vizinhos$id) { gh_route_alt(id, route_options = route_options) }\n",
    "#   # Rodar função para todos os arquivos- multi thread (Jupyter)\n",
    "#   (start = Sys.time())\n",
    "#   future::plan(future::multicore)\n",
    "#   invisible(future.apply::future_lapply(X   = hex_com_vizinhos$id,\n",
    "#                                         FUN = gh_route_alt,\n",
    "#                                         future.seed = TRUE))\n",
    "#   Sys.time()\n",
    "#   Sys.time() - start\n",
    "  \n",
    "#   # Remover arquivo inteiramente processado\n",
    "#   file.remove(arq) \n",
    "\n",
    "#   # Limpar memória\n",
    "#   rm(hex_com_vizinhos)  \n",
    "#   gc(T)\n",
    "    \n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb7dfe6",
   "metadata": {},
   "source": [
    "# Método 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaa5505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dividir dataframe em várias partes para rodar\n",
    "# hex_com_vizinhos <- sprintf(\"%s/00_base_para_routing_res09_26vizinhos.csv\", pasta_aoprv_alter)\n",
    "# hex_com_vizinhos <- read_delim(hex_com_vizinhos, delim = ';', col_types = cols(.default = \"c\"))\n",
    "# nrow(hex_com_vizinhos) # 10911566\n",
    "\n",
    "# hex_com_vizinhos <- hex_com_vizinhos %>% slice(1:1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40c8185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checar quais resultados já foram rodados - abrir lista, puxar ids e remover\n",
    "# # do dataframe hex_com_vizinhos se houver\n",
    "# # library('tidylog')\n",
    "# arqs_resultados <- data.frame(arq = list.files(pasta_rts_aopt_19, recursive = FALSE, full.names = FALSE))\n",
    "# arqs_resultados <- arqs_resultados %>% mutate(hex_id = str_replace(arq, '_modalt.csv', ''))\n",
    "# hex_com_vizinhos <- hex_com_vizinhos %>% filter(!id %in% arqs_resultados$hex_id)\n",
    "# rm(arqs_resultados)\n",
    "\n",
    "# # Limpar memória\n",
    "# gc(T)\n",
    "\n",
    "# nrow(hex_com_vizinhos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a6c920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detach(\"package:tidylog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10b4ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Criar ttmatrix a partir do GrahHopper - melhor rodar no Jupyter se for AOP;\n",
    "# # se forem só as rotas originais, é ok rodar no RStudio\n",
    "# # for (id in hex_com_vizinhos$id) { gh_route_alt(id, route_options = route_options) }\n",
    "# # Rodar função para todos os arquivos- multi thread (Jupyter)\n",
    "# (start = Sys.time())\n",
    "# future::plan(future::multicore)\n",
    "# invisible(future.apply::future_lapply(X   = hex_com_vizinhos$id,\n",
    "#                                             FUN = gh_route_alt,\n",
    "#                                             future.seed = TRUE))\n",
    "# Sys.time()\n",
    "# Sys.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffcdb26",
   "metadata": {},
   "source": [
    "# Método 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e770a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detach(\"package:tidylog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2aff19ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definir intervalo que custe pouca memória do future\n",
    "# intervalo <- 50000\n",
    "# # Puxar valor de nrow(hex_com_vizinhos)\n",
    "# max_value <- 10911566\n",
    "\n",
    "# # Abrir base hex_com_vizinhos e selecionar quantidade de linhas\n",
    "# # de acordo com intervalo, checar ids que já rodaram, fazer \n",
    "# # routing com future, limpar memória e reiniciar até terminar\n",
    "# for (i in seq(1, max_value, intervalo)) {\n",
    "#   # i <- 1; \n",
    "  \n",
    "#   # Se valor máximo pelo intervalo for maior que dataframe,\n",
    "#   # considerar tamanho do dataframe como máximo\n",
    "#   interval_max <- i + intervalo - 1\n",
    "#   if (interval_max > max_value) { interval_max <- max_value}\n",
    "#   print(sprintf('%i - %i', i, interval_max))\n",
    "  \n",
    "#   # Abrir base para routing com 26 vizinhos, manter só id e url\n",
    "#   hex_com_vizinhos <- sprintf(\"%s/00_base_para_routing_res09_26vizinhos.csv\", pasta_aoprv_alter)\n",
    "#   hex_com_vizinhos <- read_delim(hex_com_vizinhos, delim = ';', col_types = cols(.default = \"c\"))\n",
    "#   hex_com_vizinhos <- hex_com_vizinhos %>% select(id, url)\n",
    "  \n",
    "#   # Puxar só linhas correspondentes ao intervalo\n",
    "#   hex_com_vizinhos <- hex_com_vizinhos %>% slice(i:interval_max)\n",
    "  \n",
    "#   # Checar quais resultados já foram rodados - abrir lista, puxar ids e remover\n",
    "#   # do dataframe hex_com_vizinhos se houver\n",
    "#   # library('tidylog')\n",
    "#   arqs_resultados <- data.frame(arq = list.files(pasta_rts_aopt_19, recursive = FALSE, full.names = FALSE))\n",
    "#   arqs_resultados <- arqs_resultados %>% mutate(hex_id = str_replace(arq, '_modalt.csv', ''))\n",
    "#   hex_com_vizinhos <- hex_com_vizinhos %>% filter(!id %in% arqs_resultados$hex_id)\n",
    "#   rm(arqs_resultados)\n",
    "#   # nrow(hex_com_vizinhos)\n",
    "\n",
    "#   # Limpar memória\n",
    "#   gc(T)\n",
    "  \n",
    "#   # Criar ttmatrix a partir do GrahHopper - melhor rodar no Jupyter se for AOP;\n",
    "#   # se forem só as rotas originais, é ok rodar no RStudio\n",
    "#   # for (id in hex_com_vizinhos$id) { gh_route_alt(id, route_options = route_options) }\n",
    "#   # Rodar função para todos os arquivos- multi thread (Jupyter)\n",
    "#   (start = Sys.time())\n",
    "#   future::plan(future::multicore)\n",
    "#   invisible(future.apply::future_lapply(X   = hex_com_vizinhos$id,\n",
    "#                                         FUN = gh_route_alt,\n",
    "#                                         future.seed = TRUE))\n",
    "#   Sys.time()\n",
    "#   Sys.time() - start\n",
    "  \n",
    "#   # Limpar memória\n",
    "#   rm(hex_com_vizinhos)\n",
    "#   gc(T)\n",
    "    \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85f68c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:r4_env]",
   "language": "R",
   "name": "conda-env-r4_env-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
